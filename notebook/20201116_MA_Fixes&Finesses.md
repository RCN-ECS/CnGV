# Fixes and Finesses

This post is in response to this [previous post](https://github.com/RCN-ECS/CnGV/blob/master/notebook/20201109_KEL_MA_meetingnotes.md) in which Molly went through a few lingering issues with the simulations. 

## Issue #1. GxE p-values 
The p-values for the raw data were alarmingly different from the p-values generated by the ANOVA, although some discrpancy is expected. One potential reason is that I was still testing the null that GxE = 0, not that GxE = G+E, like i had implemented with the means data. 
So I re-coded the null hypothesis for the raw data into the following: 

This also resolves one of the other issues which is to ensure that methods for means matches raw. I will triple check, but I am 99% sure this was the only "avoidable" methodological difference between means and raw. (I say avoidable because bootstrap and permutation for the means  data requires sampling a new mean, whereas we do not need to do that for the raw data)

```{G+E permutation code}

 allGE <- NULL
    for (i in 1:nlevels(input_df$gen_factor)){
      for (j in 1:nlevels(input_df$exp_env_factor)){
        
        G_levels <- levels(input_df$gen_factor)
        E_levels <- levels(input_df$exp_env_factor)
        
        Gi_mean <- mean(sample(input_df$phen_corrected[input_df$gen_factor == G_levels[i]], 
                               size = length(input_df$phen_corrected[input_df$gen_factor == G_levels[i]]),
                               replace = TRUE))
        Ej_mean <- mean(sample(input_df$phen_corrected[input_df$exp_env_factor == E_levels[j]],
                               size = length(input_df$phen_corrected[input_df$exp_env_factor == E_levels[j]]),
                               replace = TRUE))
        GE_sd <- input_df %>%
          filter(gen_factor == G_levels[i]) %>%
          filter(exp_env_factor == E_levels[j]) %>%
          summarize("GEsd" = mean(e))

        # Create a sample of the null expectation for the Gi+Ej
        set.seed = seed
        GiEj_null_samp <- rnorm(1, mean = (Gi_mean + Ej_mean), sd = abs(GE_sd[[1]]))
        
        # Estimate 
        GxE_mean.temp <- abs(GiEj_null_samp - # G+E (Phenotype of ith genotype in jth environment)
                             Gi_mean - # mean phenotype of ith Genotype
                             Ej_mean + # mean phenotype of jth Environment
                             mean(input_df$phen_corrected)) # Overall mean
        allGE <- c(allGE, GxE_mean.temp)
      }
    }
    
    GxE_emm_loop = mean(allGE)
```

I ran a quick replicate (which wasn't at all quick, because I had to do a TON of debugging after making these changes... ) and now get the following for the GxE: (loess fits to total sample size visualize general patterns)

#### What does this tell me: 
In combination with the heatmaps below (See Issue #3) is that most of these weird values occur in the low sample size. As you see below, I suggest leaving that treatment out to refine false pos and negs.

#### KEL note: These plots make it look to me like total sample size is driving weird patterns, could you color by total sample size to check? It would save time to remove all the sims with low sample sizes (e.g. less than 30 or something like that).

![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.GxE.EmmvsAnova.png)

To double check that the issue was with permutation and not the way we calculate error, I again compare confidence intervals. The plots look okay to me. This probably means if a problem in p-value lingers, its likely in the way we're estimating p-values, not error.  
![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.GxE_ConfIntervals.png)

## Issue #2: Population vs. Sample estimates. 
We identified an issue in our actual (i.e. population) vs. estimated (i.e., sample) covariance estimations. The function cov() in r is a sample estimator, and thus uses the denominator of n-1 to calculate covariance. 

#### KEL note: Can you confirm that the input_df for the population is based on the true G_mean and E_means (without error), while the sample estimate is based on the data?

I fixed this by creating my own manual function to calculate covariance for samples and for population level. I still keep the cov() as a sanity check, since my function should give the exact same Cov estimates for samples. New function below:  
```{function}
cov.function <- function(input_df, is.sample){ # input_df = cov_matrix of G_means and E_means
  N = length(input_df$gen_factor)
  overallmean = mean(c(input_df$G_means,input_df$E_means))
  numerator = sum((input_df$G_means - overallmean)*(input_df$E_means - overallmean))

  if(is.sample == TRUE){
    cv = (1/(N-1))*numerator
  }else{
    cv = (1/(N))*numerator
  }
  return(cv)
}
```
## Issue #3: Find the False Positives! 
And the false negatives, and the true negatives... 
I created these heatmaps to better delineate which designs are driving different error types to hone in our sampling a bit better. 

Top number is the percent (higher percent = condition found more frequently in that group), bottom number is total sample size. The intensity of the color is not standardized, although in general, lighter blue is a bigger percent.

#### Conclusions from below plots
It appears that when sample size is 2, predictive ability swings around wildly with lots of false negatives and positives. This is expected. I wonder if we should drop the sample size of 2 in the simulations? 

#### KEL note: I agree that we should drop sample size = 2. However, I think there is a problem with the rate calculations here. There are different ways to do it, but if the question is _what are the error rates for this design?_ then the 4 rates in the same cell position should add up to 100%. What are these percentages based on?

#### Raw data - Full Reciprocal Transplant 
| --- | Covariance | GxE |
|---|---|---|
|Bootstrap|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.17.CovBootHeat.png)|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.17.GxEBootHeat.png)|
|Permutation|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.17.CovPermHeat.png)|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.17.GxEPermHeat.png)|

#### Raw data - Paired Common Garden
| --- | Covariance | GxE |
|---|---|---|
|Bootstrap|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.CovBootHeat_dub.png)|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.gxebootHeat_dub.png)|
|Permutation|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.CovPermHeat_dub.png)|![image](https://github.com/RCN-ECS/CnGV/blob/master/results/notebook_figs/11.16.GxEPermHeat_dub.png)|

## Issue #4: Make confusion matrix for Anova 

## KEL note: This also passes my sanity check. Keep in mind that our approach is not near the nominal rate (ANOVA has the 5% FPR, which is expected), so we can argue that this approach is conservative (a lower FPR at the expense of a higher FNR).

**Sanity Check for GxE** 
Anova continues to perform well. Looks sane to me. 

| | Anova | Bootstrap | Permutation |
| --- | --- | --- | --- |
| False Negative | 961 - 8.6 % | 91 - 0.81% | 2859 - 25.56% |
| False Positive | 135 - 1.2% | 2355 - 21.1% | 4 - 0.04% |
| True Negative | 2670 - 23.87% | 450 - 3.6% | 2801 - 25.04% |
| True Positive | 7419 - 66.3% | 8289 - 74.12% | 5521 - 49.36% |
| --- | ---| --- | --- |
| False Negative Rate | 0.11 | 0.01 | 0.34 |
| False Positive Rate | 0.048 | 0.84 | 0.001 |

## Issue #5: Targeted sampling of parameter space

## KEL note: to help with this, I need more information on what was tried previously and what your rationale is for these choices. I know we switched to the shotgun approach because the parameter space was not well sampled. The points 1 and 2 below look good, but I don't follow the rationale for 3. Is the delta_env randomly sampled? 

I will generate a dataframe of starting parameters with the following per replicate (I run 10 replicates in total) 

1. Cov = 0 x 100 (N = 1000 for False positive rates) 
2. GxE = 0 x 100 (N = 1000 for False positive rates)
3. Scaled gradient of clustering for paired common garden design (to ensure broader CovGE's are sampled)

Otherwise: 
```{params}
param_list <- list( 
  reps = c(10), 
  delta_env = NULL, 
  delta_gen = c(-1,0.0,1),
  sample_size = c(4,8,16), 
  n_pop = c(2,4,8,16),
  env_scenario = c(1,2),  # 1 = Recip. Transplant ; 2 = Common Garden
  std_dev= c(.5, 1),
  interaction = NULL) 
```
